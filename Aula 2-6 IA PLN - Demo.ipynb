{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JdelQOET5rDj"
   },
   "source": [
    "#**Processamento de Linguagem Natural**\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VaLZoauH4KXg"
   },
   "source": [
    "## DOCUMENTO / CORPUS\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "d4CKjpwJ2DD2",
    "outputId": "12ceffe9-b05c-4f7e-c275-8345f2a8f250"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sobre MBA? Eu gostei muito do MBA da FIAP</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            text     class\n",
       "0      Sobre MBA? Eu gostei muito do MBA da FIAP  positivo\n",
       "1  O MBA da FIAP pode melhorar, não gostei muito  negativo"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Documento e Corpus\n",
    "df = pd.DataFrame({\n",
    "    'text': [\n",
    "      'Sobre MBA? Eu gostei muito do MBA da FIAP',\n",
    "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
    "    ],\n",
    "    'class': [\n",
    "        'positivo',\n",
    "        'negativo'\n",
    "    ]})\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x3Kb4Wb2elpd"
   },
   "source": [
    "## TOKENIZAÇÃO\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WZoqP0WKfm2d",
    "outputId": "2c09a14f-a027-48bc-8f7b-af38d16aee0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anderson', 'Vieira', 'Dourado']\n",
      "['Anderson', 'Vieira', 'Dourado']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# aplica em uma string\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "nome = 'Anderson Vieira Dourado'\n",
    "\n",
    "print(word_tokenize(nome))\n",
    "print(nome.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA79KVRcg2Di",
    "outputId": "6d4de6b3-c72b-411b-ca9e-dfe0e2091ae0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['um', 'dois,', 'três']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[['Anderson', 'Vieira', 'Dourado'], ['um', 'dois,', 'três']]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica em uma lista\n",
    "texto = ['Anderson Vieira Dourado','um dois, três']\n",
    "type(texto)\n",
    "\n",
    "# usando o split\n",
    "print(texto[1].split())\n",
    "[t.split() for t in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iXRuWWdjkZtr",
    "outputId": "4df14494-cfbe-4bd1-e569-9977c6844dca"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Anderson', 'Vieira', 'Dourado'], ['um', 'dois', ',', 'três']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#from nltk.tokenize import word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "[word_tokenize(t) for t in texto]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "weMWMKoGljZx",
    "outputId": "017c7b60-525c-448f-b91a-190185ed3c58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    [Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...\n",
      "1    [O, MBA, da, FIAP, pode, melhorar, ,, não, gos...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Em um dataframe\n",
    "#from nltk.tokenize import word_tokenize\n",
    "#import nltk\n",
    "#nltk.download('punkt')\n",
    "\n",
    "print(df.text.apply(word_tokenize))\n",
    "\n",
    "df['tokens'] = df.text.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y9ws_prkmJUz",
    "outputId": "5abfa304-a8f2-4410-a8a0-6e5b697d26e4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Anderson Vieira.', 'Dourado']\n",
      "[['Anderson', 'Vieira', '.'], ['Dourado']]\n"
     ]
    }
   ],
   "source": [
    "# Em uma sentança (representada pelo ponto final)\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "\n",
    "s = 'Anderson Vieira.\\nDourado'\n",
    "\n",
    "print(sent_tokenize(s))\n",
    "print([word_tokenize(t) for t in sent_tokenize(s)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "VAo3WqWhjfg1"
   },
   "outputs": [],
   "source": [
    "#from nltk.tokenize import wordpunct_tokenize (separa por qualquer pontuação, inclusive números R$3,50 = 'R','$','3',',','50')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqCkOL0C5-FC"
   },
   "source": [
    "## UNIGRAMA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1rhnMqaq6Bgc",
    "outputId": "d00d50cb-43ad-4aff-8e9b-b05cfa2aeb57"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Sobre MBA? Eu gostei muito do MBA da FIAP\n",
       "1    O MBA da FIAP pode melhorar, não gostei muito\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G6kSv69h2jKs",
    "outputId": "d3fbafeb-f34d-452c-d299-ea80f53d015d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   da  do  eu  fiap  gostei  mba  melhorar  muito  não  pode  sobre\n",
      "0   1   1   1     1       1    2         0      1    0     0      1\n",
      "1   1   0   0     1       1    1         1      1    1     1      0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df.text)\n",
    "text_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqaSvPft7oMJ",
    "outputId": "728ed3e7-3892-4d88-f46b-7484a8d88652"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x11 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 16 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHfqBTzH6LQm"
   },
   "source": [
    "## BIGRAMA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qDLdamcR2q4e",
    "outputId": "22f1cc67-92a0-4d46-dcf3-c7ea1a3a62fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   da fiap  do mba  eu gostei  fiap pode  gostei muito  mba da  mba eu  melhorar não  muito do  não gostei  pode melhorar  sobre mba\n",
      "0        1       1          1          0             1       1       1             0         1           0              0          1\n",
      "1        1       0          0          1             1       1       0             1         0           1              1          0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df.text)\n",
    "text_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QIFnNUdM6SvU"
   },
   "source": [
    "## TRIGRAMA\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xalnPjjG2u7k",
    "outputId": "18ab5a4a-82b1-42bd-94c9-fbabb1d11e96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     0  1\n",
      "da fiap pode         0  1\n",
      "do mba da            1  0\n",
      "eu gostei muito      1  0\n",
      "fiap pode melhorar   0  1\n",
      "gostei muito do      1  0\n",
      "mba da fiap          1  1\n",
      "mba eu gostei        1  0\n",
      "melhorar não gostei  0  1\n",
      "muito do mba         1  0\n",
      "não gostei muito     0  1\n",
      "pode melhorar não    0  1\n",
      "sobre mba eu         1  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,3))\n",
    "vect.fit(df.text)\n",
    "text_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).T.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "swmx7vR65mdb"
   },
   "source": [
    "## REGEX\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "9YlTu0v36jmy"
   },
   "outputs": [],
   "source": [
    "email = \"dourado@gmail.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "0DLpiJZvUT86",
    "outputId": "c1d4ebaf-4f3b-432c-d60a-0ca99047057d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gmail'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# função split do Python\n",
    "email.split(\"@\")[1].split(\".\")[0]\n",
    "\n",
    "#\"dourado@gmail.com\".split(\"@\")[1].split('.')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "QLP8WEzi_i7j",
    "outputId": "28d85a32-c9f0-4bfb-d5d3-03ed338605ef"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' gmail '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"dourado @ gmail . com\".split(\"@\")[1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LSUYkTSFEK7l",
    "outputId": "b1ffafb7-269b-4cf6-9252-0d13ca5edc80"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gmail']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# importa pacote de regular expression\n",
    "import re\n",
    "\n",
    "regex = r\"(?<=@)[^.]+(?=\\.)\"\n",
    "re.findall(regex, email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oP7VTbtgDkYq",
    "outputId": "4aa6dbe5-ff69-4af6-aa34-56877ff2bc04"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.128011100000009, 1.1024253999999871]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mede o tempo de execução de um trecho de código\n",
    "import timeit\n",
    "\n",
    "timeit.Timer(\n",
    " 're.findall(regex, \"dourado@gmail.com\")',\n",
    " 'import re; regex = r\"(?<=@)[^.]+(?=\\.)\"'\n",
    ").repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBmaBfknD0l7",
    "outputId": "273a65a3-0a88-4234-d943-4f4f502b39c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.31946919999998613, 0.3235792000000117]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timeit\n",
    "\n",
    "timeit.Timer(\n",
    " '\"dourado@gmail.com\".split(\"@\")[1].split(\".\")[0]'\n",
    ").repeat(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "u_0q3goBYfGJ"
   },
   "outputs": [],
   "source": [
    "import antigravity\n",
    "\n",
    "#Abrir o site: https://xkcd.com/353/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OiOFT26cD-W6",
    "outputId": "d22511a7-dff9-4215-8b49-472d7172de5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Zen of Python, by Tim Peters\n",
      "\n",
      "Beautiful is better than ugly.\n",
      "Explicit is better than implicit.\n",
      "Simple is better than complex.\n",
      "Complex is better than complicated.\n",
      "Flat is better than nested.\n",
      "Sparse is better than dense.\n",
      "Readability counts.\n",
      "Special cases aren't special enough to break the rules.\n",
      "Although practicality beats purity.\n",
      "Errors should never pass silently.\n",
      "Unless explicitly silenced.\n",
      "In the face of ambiguity, refuse the temptation to guess.\n",
      "There should be one-- and preferably only one --obvious way to do it.\n",
      "Although that way may not be obvious at first unless you're Dutch.\n",
      "Now is better than never.\n",
      "Although never is often better than *right* now.\n",
      "If the implementation is hard to explain, it's a bad idea.\n",
      "If the implementation is easy to explain, it may be a good idea.\n",
      "Namespaces are one honking great idea -- let's do more of those!\n"
     ]
    }
   ],
   "source": [
    "import this"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "poR8p3MAKOIG"
   },
   "source": [
    "    Bonito é melhor que feio.\n",
    "    Explícito é melhor que implícito.\n",
    "    Simples é melhor que Complexo.\n",
    "    Complexo é melhor que complicado.\n",
    "    Achatado é melhor que aninhado.\n",
    "    Disperso é melhor que compacto.\n",
    "    Legibilidade conta.\n",
    "    Casos especiais não são especiais o suficiente para quebrar as regras.\n",
    "    Apesar de praticidade vencer a pureza.\n",
    "    Erros nunca devem passar despercebidos.\n",
    "    A menos que passem explicitamente \"despercebidos\".\n",
    "    Diante de ambiguidades, recuse a tentação de deduzir.\n",
    "    Deve haver uma --e preferencialmente só uma-- maneira fácil de fazer isto.\n",
    "    Apesar de que a maneira não pode ser óbvia de primeira, a não ser que você seja \"asiático\".\n",
    "    Agora é melhor do que nunca.\n",
    "    Porém, muitas vezes nunca é melhor do que *agora*.\n",
    "    Se a implementação é difícil de explicar, é uma péssima ideia.\n",
    "    Se a implementação é fácil de explicar, pode ser uma boa ideia.\n",
    "    Namespaces são uma grande ideia gritante -- vamos fazer mais dessas!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GzrIMF-vkQUW"
   },
   "source": [
    "Caracteres ou metacaracteres\n",
    "\n",
    "    meta - O que faz?\n",
    "    ---------------------\n",
    "    . - Qualquer caractere\n",
    "    [] - Lista de caracteres\n",
    "    [^] - Lista negada\n",
    "    ? - Anterior pode existir ou não\n",
    "    .* - Qualquer coisa\n",
    "    {x} - Anterior aparece x vezes\n",
    "    $ - Fim da linha\n",
    "    + - Anterior ao menos ums vez\n",
    "    (xy) - Cria grupos\n",
    "    ^ - Começo da linha\n",
    "    \\ - escapa o meta (ignora)\n",
    "    | - ou\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UHiGfhPskQDH",
    "outputId": "33613244-04e9-42c7-f35f-fa3778c1acbc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "#email\n",
    "re.findall(r'.',email)\n",
    "re.findall(r'[a-z]',email)\n",
    "re.findall(r'[0-9]',email)\n",
    "re.findall(r'.*',email)\n",
    "re.findall(r'$',email)\n",
    "\n",
    "re.findall(r'[a-z]+',email)\n",
    "\n",
    "re.findall(r'^.',email)\n",
    "re.findall(r'^d',email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SSK6DZRdmKo8"
   },
   "source": [
    "## STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hp5M3u_XrGqY",
    "outputId": "7196b2da-c194-47c0-80e1-ee0cd9796f43"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('portuguese')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "IB8EYOCU9--r",
    "outputId": "f59ae3af-922f-4315-ab8a-628ed08fc5a4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aos'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove uma stopword da lista\n",
    "stops.pop(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "N-gT5nMg91FW",
    "outputId": "bc93feba-1533-4fd5-fbb0-6db3764f0d95"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'às']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista as 10 primeiras stopwords\n",
    "stops[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "GoE1kJ6UZ_oA"
   },
   "outputs": [],
   "source": [
    "# podemos criar nossa propria lista\n",
    "stops = stops + [\"anderson\", \"fiap\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3vvZzFQS9zjq",
    "outputId": "aea66c28-3cb9-46e2-cdd9-8838cce0f3d0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'à',\n",
       " 'ao',\n",
       " 'aquela',\n",
       " 'aquelas',\n",
       " 'aquele',\n",
       " 'aqueles',\n",
       " 'aquilo',\n",
       " 'as',\n",
       " 'às',\n",
       " 'até',\n",
       " 'com',\n",
       " 'como',\n",
       " 'da',\n",
       " 'das',\n",
       " 'de',\n",
       " 'dela',\n",
       " 'delas',\n",
       " 'dele',\n",
       " 'deles',\n",
       " 'depois',\n",
       " 'do',\n",
       " 'dos',\n",
       " 'e',\n",
       " 'é',\n",
       " 'ela',\n",
       " 'elas',\n",
       " 'ele',\n",
       " 'eles',\n",
       " 'em',\n",
       " 'entre',\n",
       " 'era',\n",
       " 'eram',\n",
       " 'éramos',\n",
       " 'essa',\n",
       " 'essas',\n",
       " 'esse',\n",
       " 'esses',\n",
       " 'esta',\n",
       " 'está',\n",
       " 'estamos',\n",
       " 'estão',\n",
       " 'estar',\n",
       " 'estas',\n",
       " 'estava',\n",
       " 'estavam',\n",
       " 'estávamos',\n",
       " 'este',\n",
       " 'esteja',\n",
       " 'estejam',\n",
       " 'estejamos',\n",
       " 'estes',\n",
       " 'esteve',\n",
       " 'estive',\n",
       " 'estivemos',\n",
       " 'estiver',\n",
       " 'estivera',\n",
       " 'estiveram',\n",
       " 'estivéramos',\n",
       " 'estiverem',\n",
       " 'estivermos',\n",
       " 'estivesse',\n",
       " 'estivessem',\n",
       " 'estivéssemos',\n",
       " 'estou',\n",
       " 'eu',\n",
       " 'foi',\n",
       " 'fomos',\n",
       " 'for',\n",
       " 'fora',\n",
       " 'foram',\n",
       " 'fôramos',\n",
       " 'forem',\n",
       " 'formos',\n",
       " 'fosse',\n",
       " 'fossem',\n",
       " 'fôssemos',\n",
       " 'fui',\n",
       " 'há',\n",
       " 'haja',\n",
       " 'hajam',\n",
       " 'hajamos',\n",
       " 'hão',\n",
       " 'havemos',\n",
       " 'haver',\n",
       " 'hei',\n",
       " 'houve',\n",
       " 'houvemos',\n",
       " 'houver',\n",
       " 'houvera',\n",
       " 'houverá',\n",
       " 'houveram',\n",
       " 'houvéramos',\n",
       " 'houverão',\n",
       " 'houverei',\n",
       " 'houverem',\n",
       " 'houveremos',\n",
       " 'houveria',\n",
       " 'houveriam',\n",
       " 'houveríamos',\n",
       " 'houvermos',\n",
       " 'houvesse',\n",
       " 'houvessem',\n",
       " 'houvéssemos',\n",
       " 'isso',\n",
       " 'isto',\n",
       " 'já',\n",
       " 'lhe',\n",
       " 'lhes',\n",
       " 'mais',\n",
       " 'mas',\n",
       " 'me',\n",
       " 'mesmo',\n",
       " 'meu',\n",
       " 'meus',\n",
       " 'minha',\n",
       " 'minhas',\n",
       " 'muito',\n",
       " 'na',\n",
       " 'não',\n",
       " 'nas',\n",
       " 'nem',\n",
       " 'no',\n",
       " 'nos',\n",
       " 'nós',\n",
       " 'nossa',\n",
       " 'nossas',\n",
       " 'nosso',\n",
       " 'nossos',\n",
       " 'num',\n",
       " 'numa',\n",
       " 'o',\n",
       " 'os',\n",
       " 'ou',\n",
       " 'para',\n",
       " 'pela',\n",
       " 'pelas',\n",
       " 'pelo',\n",
       " 'pelos',\n",
       " 'por',\n",
       " 'qual',\n",
       " 'quando',\n",
       " 'que',\n",
       " 'quem',\n",
       " 'são',\n",
       " 'se',\n",
       " 'seja',\n",
       " 'sejam',\n",
       " 'sejamos',\n",
       " 'sem',\n",
       " 'ser',\n",
       " 'será',\n",
       " 'serão',\n",
       " 'serei',\n",
       " 'seremos',\n",
       " 'seria',\n",
       " 'seriam',\n",
       " 'seríamos',\n",
       " 'seu',\n",
       " 'seus',\n",
       " 'só',\n",
       " 'somos',\n",
       " 'sou',\n",
       " 'sua',\n",
       " 'suas',\n",
       " 'também',\n",
       " 'te',\n",
       " 'tem',\n",
       " 'tém',\n",
       " 'temos',\n",
       " 'tenha',\n",
       " 'tenham',\n",
       " 'tenhamos',\n",
       " 'tenho',\n",
       " 'terá',\n",
       " 'terão',\n",
       " 'terei',\n",
       " 'teremos',\n",
       " 'teria',\n",
       " 'teriam',\n",
       " 'teríamos',\n",
       " 'teu',\n",
       " 'teus',\n",
       " 'teve',\n",
       " 'tinha',\n",
       " 'tinham',\n",
       " 'tínhamos',\n",
       " 'tive',\n",
       " 'tivemos',\n",
       " 'tiver',\n",
       " 'tivera',\n",
       " 'tiveram',\n",
       " 'tivéramos',\n",
       " 'tiverem',\n",
       " 'tivermos',\n",
       " 'tivesse',\n",
       " 'tivessem',\n",
       " 'tivéssemos',\n",
       " 'tu',\n",
       " 'tua',\n",
       " 'tuas',\n",
       " 'um',\n",
       " 'uma',\n",
       " 'você',\n",
       " 'vocês',\n",
       " 'vos',\n",
       " 'anderson',\n",
       " 'fiap']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lista todas as stopwords\n",
    "stops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VI2P65ED96Vp",
    "outputId": "f0388f5d-33d8-40f5-ffc0-4e465e466e65"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nhi1oSyK6ekI",
    "outputId": "351c8fe7-0de3-49b1-bcd5-9a883687cc83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          0  1\n",
      "gostei    1  1\n",
      "melhorar  0  1\n",
      "pode      0  1\n",
      "sobre     1  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Aplicando a utilização das stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "stops = nltk.corpus.stopwords.words('portuguese') + [\"fiap\"] + [\"mba\"]\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops)\n",
    "vect.fit(df.text)\n",
    "text_vect = vect.transform(df.text)\n",
    "\n",
    "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).T.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "niXXv3e-6kb0",
    "outputId": "3c66ac63-b8ea-48a7-d9cd-81a28aa870f9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Sc4YJdb96m5z",
    "outputId": "cfd5fd10-44cf-48a1-e385-99a0a667051a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'à', 'ao', 'aos', 'aquela', 'aquelas', 'aquele', 'aqueles', 'aquilo', 'as']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.corpus.stopwords.words('portuguese')[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dj6gDOA2bxWO",
    "outputId": "7618a8e9-330a-4337-8b46-ac9ec3e471cb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "208"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(stops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Y9kNz9WXUDP"
   },
   "source": [
    "## PART-OF-SPEECH TAGGER (POS-Tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sXlbSKvRBr4u",
    "outputId": "4c9f428f-cd23-498e-9303-473c8a891ab7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Tokenizxação\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tag import pos_tag\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')\n",
    "\n",
    "doc = word_tokenize(\"John's big idea isn't all that bad.\")\n",
    "doc_tag = pos_tag(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oqqNTNCABrwk",
    "outputId": "6c61a464-80b6-4513-fca3-0fa371581218"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('John', 'NOUN'),\n",
       " (\"'s\", 'PRT'),\n",
       " ('big', 'ADJ'),\n",
       " ('idea', 'NOUN'),\n",
       " ('is', 'VERB'),\n",
       " (\"n't\", 'ADV'),\n",
       " ('all', 'DET'),\n",
       " ('that', 'DET'),\n",
       " ('bad', 'ADJ'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"),tagset='universal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Oh60rZ8NIijA"
   },
   "source": [
    "De/Para do POS Tag com o tagset='universal':\n",
    "\n",
    "- NOUN (nouns / substantivos)\n",
    "- VERB (verbs / verbos)\n",
    "- ADJ (adjectives / adjetivos)\n",
    "- ADV (adverbs / advérbios)\n",
    "- PRON (pronouns / pronomes)\n",
    "- DET (determiners and articles / determinantes e artigos)\n",
    "- ADP (adpositions - prepositions and postpositions / adições - preposições e postposições)\n",
    "- NUM (numerals / numerais)\n",
    "- CONJ (conjunctions / conjunções)\n",
    "- PRT (particles / partículas)\n",
    "- . (punctuation marks / sinais de pontuação)\n",
    "- X (a catch-all for other categories such as abbreviations or foreign words / um exemplo geral para outras categorias, como abreviações ou palavras estrangeiras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lEkLwe40E71L",
    "outputId": "f98ca2c6-e352-41e2-89a9-8f6066761c62"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package universal_tagset to\n",
      "[nltk_data]     C:\\Users\\logonrmlocal\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package universal_tagset is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('universal_tagset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 108
    },
    "id": "7AVtgwMEBk-M",
    "outputId": "647a0aad-b1b7-472d-ac9f-525ba7e8366e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...</td>\n",
       "      <td>Sobre MBA? Eu gostei muito do MBA da FIAP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[O, MBA, da, FIAP, pode, melhorar, ,, não, gos...</td>\n",
       "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tokens  \\\n",
       "0  [Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...   \n",
       "1  [O, MBA, da, FIAP, pode, melhorar, ,, não, gos...   \n",
       "\n",
       "                                            text  \n",
       "0      Sobre MBA? Eu gostei muito do MBA da FIAP  \n",
       "1  O MBA da FIAP pode melhorar, não gostei muito  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizxação\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "#df['tokens'] = df.text.apply(word_tokenize)\n",
    "df[[\"tokens\",\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aRuCY82SXnQV",
    "outputId": "7222ab06-cab4-4427-ef18-127fabeaa783"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'NOUN'),\n",
       " ('MBA', 'NOUN'),\n",
       " ('da', 'NOUN'),\n",
       " ('FIAP', 'NOUN'),\n",
       " ('pode', 'NOUN'),\n",
       " ('melhorar', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('não', 'ADJ'),\n",
       " ('gostei', 'NOUN'),\n",
       " ('muito', 'NOUN')]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rotular parte do discurso\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
    "df.tags[1]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Aula 2-6 IA PLN - Demo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
