{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "22607c20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2916 entries, 0 to 4079\n",
      "Data columns (total 3 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   nome       2916 non-null   object\n",
      " 1   descricao  2916 non-null   object\n",
      " 2   categoria  2916 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 91.1+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('https://dados-ml-pln.s3-sa-east-1.amazonaws.com/produtos.csv',sep=';', on_bad_lines='skip', encoding='utf-8')\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc298477",
   "metadata": {},
   "source": [
    "> Crie uma nova coluna com a junção do nome e\n",
    "descrição dos produtos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e9bcb27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        O Hobbit - 7ª Ed. 2013 Produto NovoBilbo Bols...\n",
       "1        Livro - It A Coisa - Stephen King Produto Nov...\n",
       "2        Box  As Crônicas De Gelo E Fogo  Pocket  5 Li...\n",
       "3        Box Harry Potter Produto Novo e Físico  A sér...\n",
       "4        Livro Origem - Dan Brown Produto NovoDe Onde ...\n",
       "                              ...                        \n",
       "4073     Red Dead Redemption Edição Do Ano Goty Xbox 3...\n",
       "4074     Jogo Gta 5 Grand Theft Auto V Ps4 Mídia Cd + ...\n",
       "4075     Zelda: Breath Of The Wild - Expansion Pass - ...\n",
       "4078     Gta San Andreas Hd Remastered Ps3 Envio Imedi...\n",
       "4079     Mini Game  Nova Portátil 10mil Jogos Player M...\n",
       "Name: nome_descricao, Length: 2916, dtype: object"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['nome_descricao'] = df['nome'] + df['descricao']\n",
    "df['nome_descricao']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0e2ef7",
   "metadata": {},
   "source": [
    "> Quantos unigramas, bigramas e trigramas existem\n",
    "nessa nova coluna antes e depois de remover as\n",
    "stopwords?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dff5cf67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2916x35466 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 324388 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Unigramas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(1,1))\n",
    "vect.fit(df['nome_descricao'])\n",
    "text_vect = vect.transform(df['nome_descricao'])\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a2766cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2916x159553 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 456768 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigramas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(2,2))\n",
    "vect.fit(df['nome_descricao'])\n",
    "text_vect = vect.transform(df['nome_descricao'])\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e9a4dc04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2916x228162 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 479170 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trigramas\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vect = CountVectorizer(ngram_range=(3,3))\n",
    "vect.fit(df['nome_descricao'])\n",
    "text_vect = vect.transform(df['nome_descricao'])\n",
    "text_vect"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9c4ecf",
   "metadata": {},
   "source": [
    "> Quantos verbos e adjetivos existem na nova coluna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "359e1e31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tokens</th>\n",
       "      <th>nome_descricao</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...</td>\n",
       "      <td>O Hobbit - 7ª Ed. 2013 Produto NovoBilbo Bols...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Livro, -, It, A, Coisa, -, Stephen, King, Pro...</td>\n",
       "      <td>Livro - It A Coisa - Stephen King Produto Nov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Box, As, Crônicas, De, Gelo, E, Fogo, Pocket,...</td>\n",
       "      <td>Box  As Crônicas De Gelo E Fogo  Pocket  5 Li...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Box, Harry, Potter, Produto, Novo, e, Físico,...</td>\n",
       "      <td>Box Harry Potter Produto Novo e Físico  A sér...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Livro, Origem, -, Dan, Brown, Produto, NovoDe...</td>\n",
       "      <td>Livro Origem - Dan Brown Produto NovoDe Onde ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4073</th>\n",
       "      <td>[Red, Dead, Redemption, Edição, Do, Ano, Goty,...</td>\n",
       "      <td>Red Dead Redemption Edição Do Ano Goty Xbox 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>[Jogo, Gta, 5, Grand, Theft, Auto, V, Ps4, Míd...</td>\n",
       "      <td>Jogo Gta 5 Grand Theft Auto V Ps4 Mídia Cd + ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4075</th>\n",
       "      <td>[Zelda, :, Breath, Of, The, Wild, -, Expansion...</td>\n",
       "      <td>Zelda: Breath Of The Wild - Expansion Pass - ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4078</th>\n",
       "      <td>[Gta, San, Andreas, Hd, Remastered, Ps3, Envio...</td>\n",
       "      <td>Gta San Andreas Hd Remastered Ps3 Envio Imedi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4079</th>\n",
       "      <td>[Mini, Game, Nova, Portátil, 10mil, Jogos, Pla...</td>\n",
       "      <td>Mini Game  Nova Portátil 10mil Jogos Player M...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2916 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 tokens  \\\n",
       "0     [O, Hobbit, -, 7ª, Ed, ., 2013, Produto, NovoB...   \n",
       "1     [Livro, -, It, A, Coisa, -, Stephen, King, Pro...   \n",
       "2     [Box, As, Crônicas, De, Gelo, E, Fogo, Pocket,...   \n",
       "3     [Box, Harry, Potter, Produto, Novo, e, Físico,...   \n",
       "4     [Livro, Origem, -, Dan, Brown, Produto, NovoDe...   \n",
       "...                                                 ...   \n",
       "4073  [Red, Dead, Redemption, Edição, Do, Ano, Goty,...   \n",
       "4074  [Jogo, Gta, 5, Grand, Theft, Auto, V, Ps4, Míd...   \n",
       "4075  [Zelda, :, Breath, Of, The, Wild, -, Expansion...   \n",
       "4078  [Gta, San, Andreas, Hd, Remastered, Ps3, Envio...   \n",
       "4079  [Mini, Game, Nova, Portátil, 10mil, Jogos, Pla...   \n",
       "\n",
       "                                         nome_descricao  \n",
       "0      O Hobbit - 7ª Ed. 2013 Produto NovoBilbo Bols...  \n",
       "1      Livro - It A Coisa - Stephen King Produto Nov...  \n",
       "2      Box  As Crônicas De Gelo E Fogo  Pocket  5 Li...  \n",
       "3      Box Harry Potter Produto Novo e Físico  A sér...  \n",
       "4      Livro Origem - Dan Brown Produto NovoDe Onde ...  \n",
       "...                                                 ...  \n",
       "4073   Red Dead Redemption Edição Do Ano Goty Xbox 3...  \n",
       "4074   Jogo Gta 5 Grand Theft Auto V Ps4 Mídia Cd + ...  \n",
       "4075   Zelda: Breath Of The Wild - Expansion Pass - ...  \n",
       "4078   Gta San Andreas Hd Remastered Ps3 Envio Imedi...  \n",
       "4079   Mini Game  Nova Portátil 10mil Jogos Player M...  \n",
       "\n",
       "[2916 rows x 2 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenizxação\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "df['tokens'] = df['nome_descricao'].apply(word_tokenize)\n",
    "df[[\"tokens\",\"nome_descricao\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4907769b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Livro', 'NOUN'),\n",
       " ('-', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('A', 'DET'),\n",
       " ('Coisa', 'NOUN'),\n",
       " ('-', '.'),\n",
       " ('Stephen', 'NOUN'),\n",
       " ('King', 'NOUN'),\n",
       " ('Produto', 'NOUN'),\n",
       " ('NovoDurante', 'NOUN'),\n",
       " ('as', 'ADP'),\n",
       " ('férias', 'ADJ'),\n",
       " ('escolares', 'NOUN'),\n",
       " ('de', 'ADP'),\n",
       " ('1958', 'NUM'),\n",
       " (',', '.'),\n",
       " ('em', 'X'),\n",
       " ('Derry', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('pacata', 'NOUN'),\n",
       " ('cidadezinha', 'NOUN'),\n",
       " ('do', 'VERB'),\n",
       " ('Maine', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Bill', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Richie', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Stan', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Mike', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Eddie', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('Ben', 'NOUN'),\n",
       " ('e', 'VERB'),\n",
       " ('Beverly', 'NOUN'),\n",
       " ('aprenderam', 'NOUN'),\n",
       " ('o', 'NOUN'),\n",
       " ('real', 'ADJ'),\n",
       " ('sentido', 'NOUN'),\n",
       " ('da', 'NOUN'),\n",
       " ('amizade', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('do', 'VERB'),\n",
       " ('amor', 'ADV'),\n",
       " (',', '.'),\n",
       " ('da', 'NOUN'),\n",
       " ('confiança', 'NOUN'),\n",
       " ('e', 'NOUN'),\n",
       " ('...', '.'),\n",
       " ('do', 'VERB'),\n",
       " ('medo', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('O', 'NOUN'),\n",
       " ('mais', 'VERB'),\n",
       " ('profundo', 'ADJ'),\n",
       " ('e', 'NOUN'),\n",
       " ('tenebroso', 'NOUN'),\n",
       " ('medo', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Naquele', 'NOUN'),\n",
       " ('verão', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('eles', 'VERB'),\n",
       " ('enfrentaram', 'X'),\n",
       " ('pela', 'NOUN'),\n",
       " ('primeira', 'NOUN'),\n",
       " ('vez', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('Coisa', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('um', 'ADJ'),\n",
       " ('ser', 'NOUN'),\n",
       " ('sobrenatural', 'ADJ'),\n",
       " ('e', 'NOUN'),\n",
       " ('maligno', 'NOUN'),\n",
       " ('que', 'NOUN'),\n",
       " ('deixou', 'NOUN'),\n",
       " ('terríveis', 'NOUN'),\n",
       " ('marcas', 'NOUN'),\n",
       " ('de', 'ADP'),\n",
       " ('sangue', 'X'),\n",
       " ('em', 'NOUN'),\n",
       " ('Derry', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Quase', 'NOUN'),\n",
       " ('trinta', 'ADJ'),\n",
       " ('anos', 'NOUN'),\n",
       " ('depois', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('os', 'ADJ'),\n",
       " ('amigos', 'NOUN'),\n",
       " ('voltam', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('se', 'ADJ'),\n",
       " ('encontrar', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Uma', 'NOUN'),\n",
       " ('nova', 'ADJ'),\n",
       " ('onda', 'NOUN'),\n",
       " ('de', 'ADP'),\n",
       " ('terror', 'NOUN'),\n",
       " ('tomou', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('pequena', 'NOUN'),\n",
       " ('cidade', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Mike', 'NOUN'),\n",
       " ('Hanlon', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('o', 'ADJ'),\n",
       " ('único', 'NOUN'),\n",
       " ('que', 'NOUN'),\n",
       " ('permanece', 'NOUN'),\n",
       " ('em', 'NOUN'),\n",
       " ('Derry', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('dá', 'NOUN'),\n",
       " ('o', 'ADJ'),\n",
       " ('sinal', 'ADJ'),\n",
       " ('.', '.'),\n",
       " ('Precisam', 'NOUN'),\n",
       " ('unir', 'ADJ'),\n",
       " ('forças', 'NOUN'),\n",
       " ('novamente', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('A', 'DET'),\n",
       " ('Coisa', 'NOUN'),\n",
       " ('volta', 'NOUN'),\n",
       " ('a', 'DET'),\n",
       " ('atacar', 'NOUN'),\n",
       " ('e', 'NOUN'),\n",
       " ('eles', 'NOUN'),\n",
       " ('devem', 'VERB'),\n",
       " ('cumprir', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('promessa', 'NOUN'),\n",
       " ('selada', 'NOUN'),\n",
       " ('com', 'NOUN'),\n",
       " ('sangue', 'NOUN'),\n",
       " ('que', 'NOUN'),\n",
       " ('fizeram', 'NOUN'),\n",
       " ('quando', 'NOUN'),\n",
       " ('crianças', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Só', 'NOUN'),\n",
       " ('eles', 'VERB'),\n",
       " ('têm', 'VERB'),\n",
       " ('a', 'DET'),\n",
       " ('chave', 'NOUN'),\n",
       " ('do', 'NOUN'),\n",
       " ('enigma', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Só', 'NOUN'),\n",
       " ('eles', 'VERB'),\n",
       " ('sabem', 'X'),\n",
       " ('o', 'ADJ'),\n",
       " ('que', 'NOUN'),\n",
       " ('se', 'NOUN'),\n",
       " ('esconde', 'NOUN'),\n",
       " ('nas', 'NOUN'),\n",
       " ('entranhas', 'X'),\n",
       " ('de', 'X'),\n",
       " ('Derry', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('O', 'NOUN'),\n",
       " ('tempo', 'ADJ'),\n",
       " ('é', 'NOUN'),\n",
       " ('curto', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('mas', 'X'),\n",
       " ('somente', 'NOUN'),\n",
       " ('eles', 'NOUN'),\n",
       " ('podem', 'VERB'),\n",
       " ('vencer', 'ADP'),\n",
       " ('a', 'DET'),\n",
       " ('Coisa', 'NOUN'),\n",
       " ('.', '.'),\n",
       " ('Em', 'NOUN'),\n",
       " ('``', '.'),\n",
       " ('It', 'PRON'),\n",
       " ('-', '.'),\n",
       " ('A', 'DET'),\n",
       " ('Coisa', 'NOUN'),\n",
       " (\"''\", '.'),\n",
       " (',', '.'),\n",
       " ('clássico', 'X'),\n",
       " ('de', 'X'),\n",
       " ('Stephen', 'NOUN'),\n",
       " ('King', 'NOUN'),\n",
       " ('em', 'NOUN'),\n",
       " ('nova', 'NOUN'),\n",
       " ('edição', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('os', 'ADJ'),\n",
       " ('amigos', 'NOUN'),\n",
       " ('irão', 'NOUN'),\n",
       " ('até', 'NOUN'),\n",
       " ('o', 'NOUN'),\n",
       " ('fim', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('mesmo', 'NOUN'),\n",
       " ('que', 'NOUN'),\n",
       " ('isso', 'NOUN'),\n",
       " ('signifique', 'NOUN'),\n",
       " ('ultrapassar', 'ADJ'),\n",
       " ('os', 'ADJ'),\n",
       " ('próprios', 'NOUN'),\n",
       " ('limites.CaracterísticasAutor', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('King', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('StephenPeso', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('1.44I.S.B.N', 'NUM'),\n",
       " ('.', '.'),\n",
       " (':', '.'),\n",
       " ('9788560280940Altura', 'NUM'),\n",
       " (':', '.'),\n",
       " ('23.000000Largura', 'NUM'),\n",
       " (':', '.'),\n",
       " ('15.000000Profundidade', 'NUM'),\n",
       " (':', '.'),\n",
       " ('5.300000Idioma', 'NUM'),\n",
       " (':', '.'),\n",
       " ('PortuguêsAcabamento', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('0Tradutor', 'NUM'),\n",
       " (':', '.'),\n",
       " ('Winarski', 'NOUN'),\n",
       " (',', '.'),\n",
       " ('RegianeNúmero', 'NOUN'),\n",
       " ('da', 'VERB'),\n",
       " ('edição', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('0País', 'NUM'),\n",
       " ('de', 'ADP'),\n",
       " ('Origem', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('BrasilSegmento', 'NOUN'),\n",
       " (':', '.'),\n",
       " ('Ficção', 'NOUN'),\n",
       " ('-', '.'),\n",
       " ('Histórias', 'NOUN'),\n",
       " ('inquietantes', 'VERB'),\n",
       " ('-', '.'),\n",
       " ('Terror', 'NOUN')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rotular parte do discurso\n",
    "from nltk.tag import pos_tag\n",
    "\n",
    "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
    "df.tags[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "e59b5ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41954\n",
      "50845\n"
     ]
    }
   ],
   "source": [
    "def counter(linha) :\n",
    "    \n",
    "    verbos = 0\n",
    "    adjetivos = 0\n",
    "\n",
    "    for i in linha:\n",
    "        if(i[1] == 'VERB'):\n",
    "            verbos = verbos + 1\n",
    "        if(i[1] == 'ADJ'):\n",
    "            adjetivos = adjetivos + 1\n",
    "            \n",
    "    return [verbos, adjetivos]\n",
    "   \n",
    "verbos = df.tags.apply(counter)\n",
    "\n",
    "totalv =0\n",
    "totala = 0\n",
    "\n",
    "for (verbos, adj) in verbos:\n",
    "    totalv = totalv + verbos\n",
    "    totala = totala + adj\n",
    "    \n",
    "print(totalv)\n",
    "print(totala)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
